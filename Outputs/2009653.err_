INFO:    underlay of /etc/localtime required more than 50 (92) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (457) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (92) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (457) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (92) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (457) bind mounts
2023-10-06 11:23:02.273752: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2023-10-06 11:23:02.273799: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2023-10-06 11:23:02.277610: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-10-06 11:23:02.649203: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-06 11:23:25.489499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15388 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:af:00.0, compute capability: 6.0
2023-10-06 11:23:37.037374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600
2023-10-06 11:23:40.517379: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x147b80012ed0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-10-06 11:23:40.517414: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0
2023-10-06 11:23:40.530197: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-10-06 11:23:40.672125: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2023-10-06 11:23:58.293781: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer
2023-10-06 11:24:30.968540: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.
2023-10-06 11:24:30.968761: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.
2023-10-06 11:24:30.970117: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /home/abbass12/tmp/tmp1xqvx46a
2023-10-06 11:24:30.972894: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }
2023-10-06 11:24:30.972913: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /home/abbass12/tmp/tmp1xqvx46a
2023-10-06 11:24:30.977549: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled
2023-10-06 11:24:30.979228: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.
2023-10-06 11:24:31.051282: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /home/abbass12/tmp/tmp1xqvx46a
2023-10-06 11:24:31.068621: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 98505 microseconds.
