1
Tesla P100-PCIE-16GB
Instances: 7841683
Features: 80
Label
Benign                      668461
DDOS attack-HOIC            668461
DoS attacks-Hulk            434883
Bot                         282310
Infilteration               160705
SSH-Bruteforce              117322
DoS attacks-GoldenEye        41455
FTP-BruteForce               39346
DoS attacks-SlowHTTPTest     21092
DoS attacks-Slowloris        10285
DDOS attack-LOIC-UDP          1730
Brute Force -Web               609
Brute Force -XSS               230
SQL Injection                   87
Name: count, dtype: int64
Label
Benign                      668461
DDOS attack-HOIC            668461
DoS attacks-Hulk            434883
Bot                         282310
Infilteration               160705
SSH-Bruteforce              117322
DoS attacks-GoldenEye        41455
FTP-BruteForce               39346
DoS attacks-SlowHTTPTest     21092
DoS attacks-Slowloris        10285
DDOS attack-LOIC-UDP          1730
Brute Force -Web               609
Brute Force -XSS               230
SQL Injection                   87
Name: count, dtype: int64
{0: 'Benign', 1: 'Bot', 4: 'DDOS attack-HOIC', 6: 'DoS attacks-GoldenEye', 7: 'DoS attacks-Hulk', 11: 'Infilteration', 9: 'DoS attacks-Slowloris', 8: 'DoS attacks-SlowHTTPTest', 10: 'FTP-BruteForce', 13: 'SSH-Bruteforce', 2: 'Brute Force -Web', 5: 'DDOS attack-LOIC-UDP', 3: 'Brute Force -XSS', 12: 'SQL Injection'}
Intial values with Inf:          (2446976, 76)
Intial values after Inf removal: (2446778, 76)
Normalized shape: (2446778, 76) 

Shape of X_train: (1957422, 76)
Shape of y_train: (1957422,)
Shape of  X_test: (489356, 76)
Shape of  y_test: (489356,)
Type of X_train: <class 'numpy.ndarray'>
Type of y_train: <class 'numpy.ndarray'>
Type of X_test: <class 'numpy.ndarray'>
Type of y_train: <class 'numpy.ndarray'>
14
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 reshape (Reshape)           (None, 76, 1)             0         
                                                                 
 conv1d (Conv1D)             (None, 74, 64)            256       
                                                                 
 batch_normalization (Batch  (None, 74, 64)            256       
 Normalization)                                                  
                                                                 
 max_pooling1d (MaxPooling1  (None, 37, 64)            0         
 D)                                                              
                                                                 
 conv1d_1 (Conv1D)           (None, 35, 128)           24704     
                                                                 
 batch_normalization_1 (Bat  (None, 35, 128)           512       
 chNormalization)                                                
                                                                 
 max_pooling1d_1 (MaxPoolin  (None, 17, 128)           0         
 g1D)                                                            
                                                                 
 conv1d_2 (Conv1D)           (None, 15, 256)           98560     
                                                                 
 batch_normalization_2 (Bat  (None, 15, 256)           1024      
 chNormalization)                                                
                                                                 
 max_pooling1d_2 (MaxPoolin  (None, 7, 256)            0         
 g1D)                                                            
                                                                 
 flatten (Flatten)           (None, 1792)              0         
                                                                 
 dense (Dense)               (None, 128)               229504    
                                                                 
 dense_1 (Dense)             (None, 128)               16512     
                                                                 
 dense_2 (Dense)             (None, 14)                1806      
                                                                 
=================================================================
Total params: 373134 (1.42 MB)
Trainable params: 372238 (1.42 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________
Epoch 1/100
24468/24468 - 116s - loss: 0.1962 - accuracy: 0.9249 - val_loss: 0.2560 - val_accuracy: 0.9050 - 116s/epoch - 5ms/step
Epoch 2/100
24468/24468 - 105s - loss: 0.1706 - accuracy: 0.9315 - val_loss: 0.1813 - val_accuracy: 0.9321 - 105s/epoch - 4ms/step
Epoch 3/100
24468/24468 - 105s - loss: 0.1669 - accuracy: 0.9324 - val_loss: 0.1908 - val_accuracy: 0.9293 - 105s/epoch - 4ms/step
Epoch 4/100
24468/24468 - 105s - loss: 0.1668 - accuracy: 0.9322 - val_loss: 0.1942 - val_accuracy: 0.9325 - 105s/epoch - 4ms/step
Epoch 5/100
24468/24468 - 105s - loss: 0.1645 - accuracy: 0.9328 - val_loss: 0.1632 - val_accuracy: 0.9330 - 105s/epoch - 4ms/step
Epoch 6/100
24468/24468 - 105s - loss: 0.1615 - accuracy: 0.9330 - val_loss: 4836.5811 - val_accuracy: 0.2731 - 105s/epoch - 4ms/step
Epoch 7/100
24468/24468 - 105s - loss: 0.1611 - accuracy: 0.9332 - val_loss: 87.6022 - val_accuracy: 0.2928 - 105s/epoch - 4ms/step
Epoch 8/100
24468/24468 - 104s - loss: 0.1506 - accuracy: 0.9360 - val_loss: 0.1688 - val_accuracy: 0.9337 - 104s/epoch - 4ms/step
Epoch 9/100
24468/24468 - 104s - loss: 0.1452 - accuracy: 0.9378 - val_loss: 0.7720 - val_accuracy: 0.7286 - 104s/epoch - 4ms/step
Epoch 10/100
24468/24468 - 104s - loss: 0.1669 - accuracy: 0.9324 - val_loss: 0.1625 - val_accuracy: 0.9346 - 104s/epoch - 4ms/step
Epoch 11/100
24468/24468 - 104s - loss: 0.1645 - accuracy: 0.9332 - val_loss: 0.1813 - val_accuracy: 0.9251 - 104s/epoch - 4ms/step
Epoch 12/100
24468/24468 - 104s - loss: 0.1625 - accuracy: 0.9333 - val_loss: 0.1643 - val_accuracy: 0.9346 - 104s/epoch - 4ms/step
Epoch 13/100
24468/24468 - 104s - loss: 0.1619 - accuracy: 0.9334 - val_loss: 0.1687 - val_accuracy: 0.9337 - 104s/epoch - 4ms/step
Epoch 14/100
24468/24468 - 104s - loss: 0.1617 - accuracy: 0.9336 - val_loss: 0.1695 - val_accuracy: 0.9337 - 104s/epoch - 4ms/step
Epoch 15/100
24468/24468 - 104s - loss: 0.1496 - accuracy: 0.9362 - val_loss: 3.4043 - val_accuracy: 0.7253 - 104s/epoch - 4ms/step
Epoch 16/100
24468/24468 - 104s - loss: 0.1424 - accuracy: 0.9386 - val_loss: 0.1405 - val_accuracy: 0.9401 - 104s/epoch - 4ms/step
Epoch 17/100
24468/24468 - 104s - loss: 0.1441 - accuracy: 0.9381 - val_loss: 0.1405 - val_accuracy: 0.9393 - 104s/epoch - 4ms/step
Epoch 18/100
24468/24468 - 104s - loss: 0.1460 - accuracy: 0.9376 - val_loss: 0.1700 - val_accuracy: 0.9344 - 104s/epoch - 4ms/step
Epoch 19/100
24468/24468 - 104s - loss: 0.1686 - accuracy: 0.9325 - val_loss: 0.1883 - val_accuracy: 0.9318 - 104s/epoch - 4ms/step
Epoch 20/100
24468/24468 - 104s - loss: 0.1585 - accuracy: 0.9342 - val_loss: 0.1785 - val_accuracy: 0.9313 - 104s/epoch - 4ms/step
Epoch 21/100
24468/24468 - 104s - loss: 0.1503 - accuracy: 0.9366 - val_loss: 0.1772 - val_accuracy: 0.9289 - 104s/epoch - 4ms/step
Epoch 22/100
24468/24468 - 104s - loss: 0.1710 - accuracy: 0.9312 - val_loss: 0.1681 - val_accuracy: 0.9322 - 104s/epoch - 4ms/step
Epoch 23/100
24468/24468 - 104s - loss: 0.1647 - accuracy: 0.9333 - val_loss: 0.1718 - val_accuracy: 0.9334 - 104s/epoch - 4ms/step
Epoch 24/100
24468/24468 - 104s - loss: 0.1637 - accuracy: 0.9335 - val_loss: 0.2441 - val_accuracy: 0.9259 - 104s/epoch - 4ms/step
Epoch 25/100
24468/24468 - 104s - loss: 0.1620 - accuracy: 0.9337 - val_loss: 0.1619 - val_accuracy: 0.9339 - 104s/epoch - 4ms/step
Epoch 26/100
24468/24468 - 104s - loss: 0.1590 - accuracy: 0.9338 - val_loss: 0.2161 - val_accuracy: 0.9322 - 104s/epoch - 4ms/step
Epoch 27/100
24468/24468 - 104s - loss: 0.1553 - accuracy: 0.9349 - val_loss: 0.6805 - val_accuracy: 0.8757 - 104s/epoch - 4ms/step
Epoch 28/100
24468/24468 - 104s - loss: 0.1525 - accuracy: 0.9356 - val_loss: 0.2118 - val_accuracy: 0.9153 - 104s/epoch - 4ms/step
Epoch 29/100
24468/24468 - 104s - loss: 0.1475 - accuracy: 0.9371 - val_loss: 0.2448 - val_accuracy: 0.8923 - 104s/epoch - 4ms/step
Epoch 30/100
24468/24468 - 103s - loss: 0.1453 - accuracy: 0.9378 - val_loss: 0.3293 - val_accuracy: 0.8736 - 103s/epoch - 4ms/step
Epoch 31/100
24468/24468 - 103s - loss: 0.1445 - accuracy: 0.9382 - val_loss: 0.5478 - val_accuracy: 0.9325 - 103s/epoch - 4ms/step
Epoch 32/100
24468/24468 - 103s - loss: 0.1436 - accuracy: 0.9385 - val_loss: 0.1414 - val_accuracy: 0.9385 - 103s/epoch - 4ms/step
Epoch 33/100
24468/24468 - 103s - loss: 0.1430 - accuracy: 0.9386 - val_loss: 2.1337 - val_accuracy: 0.8575 - 103s/epoch - 4ms/step
Epoch 34/100
24468/24468 - 103s - loss: 0.1433 - accuracy: 0.9386 - val_loss: 0.1430 - val_accuracy: 0.9383 - 103s/epoch - 4ms/step
Epoch 35/100
24468/24468 - 103s - loss: 0.1427 - accuracy: 0.9386 - val_loss: 0.1409 - val_accuracy: 0.9404 - 103s/epoch - 4ms/step
Epoch 36/100
24468/24468 - 104s - loss: 0.1428 - accuracy: 0.9387 - val_loss: 6.7345 - val_accuracy: 0.4929 - 104s/epoch - 4ms/step
Epoch 37/100
24468/24468 - 103s - loss: 0.1425 - accuracy: 0.9385 - val_loss: 0.2805 - val_accuracy: 0.8753 - 103s/epoch - 4ms/step
15293/15293 - 22s - loss: 0.1408 - accuracy: 0.9390 - 22s/epoch - 1ms/step
Test accuracy: 93.90%
15293/15293 - 18s - 18s/epoch - 1ms/step
              precision    recall  f1-score   support

           0       0.87      0.96      0.91    133673
           1       0.99      1.00      1.00     56462
           2       0.79      0.63      0.70       122
           3       0.96      0.48      0.64        46
           4       1.00      1.00      1.00    133692
           5       1.00      0.99      1.00       346
           6       0.99      1.00      1.00      8291
           7       1.00      1.00      1.00     86977
           8       0.54      0.34      0.42      4218
           9       1.00      0.99      0.99      2057
          10       0.70      0.84      0.77      7869
          11       0.69      0.39      0.50     32121
          12       1.00      0.18      0.30        17
          13       1.00      1.00      1.00     23465

    accuracy                           0.94    489356
   macro avg       0.90      0.77      0.80    489356
weighted avg       0.93      0.94      0.93    489356

Epoch 1/100
24468/24468 - 54s - loss: 0.2307 - accuracy: 0.9144 - val_loss: 0.1920 - val_accuracy: 0.9251 - 54s/epoch - 2ms/step
Epoch 2/100
24468/24468 - 53s - loss: 0.1865 - accuracy: 0.9256 - val_loss: 0.1764 - val_accuracy: 0.9313 - 53s/epoch - 2ms/step
Epoch 3/100
24468/24468 - 53s - loss: 0.1712 - accuracy: 0.9312 - val_loss: 0.1665 - val_accuracy: 0.9327 - 53s/epoch - 2ms/step
Epoch 4/100
24468/24468 - 53s - loss: 0.1670 - accuracy: 0.9323 - val_loss: 0.1642 - val_accuracy: 0.9333 - 53s/epoch - 2ms/step
Epoch 5/100
24468/24468 - 53s - loss: 0.1650 - accuracy: 0.9329 - val_loss: 0.1628 - val_accuracy: 0.9336 - 53s/epoch - 2ms/step
Epoch 6/100
24468/24468 - 53s - loss: 0.1635 - accuracy: 0.9331 - val_loss: 0.1636 - val_accuracy: 0.9331 - 53s/epoch - 2ms/step
Epoch 7/100
24468/24468 - 53s - loss: 0.1622 - accuracy: 0.9336 - val_loss: 0.1628 - val_accuracy: 0.9340 - 53s/epoch - 2ms/step
Epoch 8/100
24468/24468 - 53s - loss: 0.1611 - accuracy: 0.9337 - val_loss: 0.1594 - val_accuracy: 0.9342 - 53s/epoch - 2ms/step
Epoch 9/100
24468/24468 - 53s - loss: 0.1600 - accuracy: 0.9338 - val_loss: 0.1640 - val_accuracy: 0.9341 - 53s/epoch - 2ms/step
Epoch 10/100
24468/24468 - 53s - loss: 0.1588 - accuracy: 0.9340 - val_loss: 0.1575 - val_accuracy: 0.9343 - 53s/epoch - 2ms/step
Epoch 11/100
24468/24468 - 53s - loss: 0.1573 - accuracy: 0.9341 - val_loss: 0.1582 - val_accuracy: 0.9349 - 53s/epoch - 2ms/step
Epoch 12/100
24468/24468 - 53s - loss: 0.1554 - accuracy: 0.9341 - val_loss: 0.1529 - val_accuracy: 0.9348 - 53s/epoch - 2ms/step
Epoch 13/100
24468/24468 - 53s - loss: 0.1535 - accuracy: 0.9344 - val_loss: 0.1505 - val_accuracy: 0.9348 - 53s/epoch - 2ms/step
Epoch 14/100
24468/24468 - 53s - loss: 0.1509 - accuracy: 0.9347 - val_loss: 0.1477 - val_accuracy: 0.9352 - 53s/epoch - 2ms/step
Epoch 15/100
24468/24468 - 53s - loss: 0.1479 - accuracy: 0.9358 - val_loss: 0.1439 - val_accuracy: 0.9409 - 53s/epoch - 2ms/step
Epoch 16/100
24468/24468 - 53s - loss: 0.1463 - accuracy: 0.9377 - val_loss: 0.1436 - val_accuracy: 0.9347 - 53s/epoch - 2ms/step
Epoch 17/100
24468/24468 - 53s - loss: 0.1436 - accuracy: 0.9388 - val_loss: 0.1395 - val_accuracy: 0.9403 - 53s/epoch - 2ms/step
Epoch 18/100
24468/24468 - 53s - loss: 0.1428 - accuracy: 0.9389 - val_loss: 0.1575 - val_accuracy: 0.9343 - 53s/epoch - 2ms/step
Epoch 19/100
24468/24468 - 53s - loss: 0.1449 - accuracy: 0.9374 - val_loss: 0.1429 - val_accuracy: 0.9349 - 53s/epoch - 2ms/step
Epoch 20/100
24468/24468 - 53s - loss: 0.1416 - accuracy: 0.9395 - val_loss: 0.1396 - val_accuracy: 0.9411 - 53s/epoch - 2ms/step
Epoch 21/100
24468/24468 - 53s - loss: 0.1404 - accuracy: 0.9399 - val_loss: 0.1673 - val_accuracy: 0.9343 - 53s/epoch - 2ms/step
Epoch 22/100
24468/24468 - 53s - loss: 0.1399 - accuracy: 0.9400 - val_loss: 0.1381 - val_accuracy: 0.9407 - 53s/epoch - 2ms/step
Epoch 23/100
24468/24468 - 53s - loss: 0.1399 - accuracy: 0.9398 - val_loss: 0.1373 - val_accuracy: 0.9413 - 53s/epoch - 2ms/step
Epoch 24/100
24468/24468 - 53s - loss: 0.1379 - accuracy: 0.9402 - val_loss: 0.1372 - val_accuracy: 0.9409 - 53s/epoch - 2ms/step
Epoch 25/100
24468/24468 - 53s - loss: 0.1377 - accuracy: 0.9403 - val_loss: 0.1368 - val_accuracy: 0.9413 - 53s/epoch - 2ms/step
Epoch 26/100
24468/24468 - 53s - loss: 0.1374 - accuracy: 0.9404 - val_loss: 0.1367 - val_accuracy: 0.9411 - 53s/epoch - 2ms/step
Epoch 27/100
24468/24468 - 53s - loss: 0.1374 - accuracy: 0.9403 - val_loss: 0.1365 - val_accuracy: 0.9413 - 53s/epoch - 2ms/step
Epoch 28/100
24468/24468 - 53s - loss: 0.1390 - accuracy: 0.9399 - val_loss: 0.1421 - val_accuracy: 0.9353 - 53s/epoch - 2ms/step
Epoch 29/100
24468/24468 - 53s - loss: 0.1376 - accuracy: 0.9403 - val_loss: 0.1382 - val_accuracy: 0.9409 - 53s/epoch - 2ms/step
Epoch 30/100
24468/24468 - 53s - loss: 0.1391 - accuracy: 0.9398 - val_loss: 0.1369 - val_accuracy: 0.9408 - 53s/epoch - 2ms/step
Epoch 31/100
24468/24468 - 53s - loss: 0.1394 - accuracy: 0.9398 - val_loss: 0.1418 - val_accuracy: 0.9373 - 53s/epoch - 2ms/step
Epoch 32/100
24468/24468 - 53s - loss: 0.1418 - accuracy: 0.9393 - val_loss: 0.1380 - val_accuracy: 0.9407 - 53s/epoch - 2ms/step
Epoch 33/100
24468/24468 - 53s - loss: 0.1378 - accuracy: 0.9402 - val_loss: 0.1356 - val_accuracy: 0.9413 - 53s/epoch - 2ms/step
Epoch 34/100
24468/24468 - 53s - loss: 0.1391 - accuracy: 0.9400 - val_loss: 0.1407 - val_accuracy: 0.9408 - 53s/epoch - 2ms/step
Epoch 35/100
24468/24468 - 53s - loss: 0.1402 - accuracy: 0.9398 - val_loss: 0.1365 - val_accuracy: 0.9412 - 53s/epoch - 2ms/step
Epoch 36/100
24468/24468 - 53s - loss: 0.1385 - accuracy: 0.9402 - val_loss: 0.1399 - val_accuracy: 0.9402 - 53s/epoch - 2ms/step
Epoch 37/100
24468/24468 - 53s - loss: 0.1365 - accuracy: 0.9405 - val_loss: 0.1356 - val_accuracy: 0.9417 - 53s/epoch - 2ms/step
Epoch 38/100
24468/24468 - 53s - loss: 0.1366 - accuracy: 0.9405 - val_loss: 0.1371 - val_accuracy: 0.9416 - 53s/epoch - 2ms/step
Epoch 39/100
24468/24468 - 53s - loss: 0.1369 - accuracy: 0.9405 - val_loss: 0.1361 - val_accuracy: 0.9407 - 53s/epoch - 2ms/step
Epoch 40/100
24468/24468 - 53s - loss: 0.1366 - accuracy: 0.9405 - val_loss: 0.1381 - val_accuracy: 0.9416 - 53s/epoch - 2ms/step
Epoch 41/100
24468/24468 - 53s - loss: 0.1367 - accuracy: 0.9405 - val_loss: 0.1358 - val_accuracy: 0.9415 - 53s/epoch - 2ms/step
Epoch 42/100
24468/24468 - 53s - loss: 0.1375 - accuracy: 0.9403 - val_loss: 0.1364 - val_accuracy: 0.9409 - 53s/epoch - 2ms/step
Epoch 43/100
24468/24468 - 53s - loss: 0.1375 - accuracy: 0.9403 - val_loss: 0.1691 - val_accuracy: 0.9347 - 53s/epoch - 2ms/step
Epoch 44/100
24468/24468 - 53s - loss: 0.1455 - accuracy: 0.9382 - val_loss: 0.1346 - val_accuracy: 0.9417 - 53s/epoch - 2ms/step
Epoch 45/100
24468/24468 - 53s - loss: 0.1391 - accuracy: 0.9402 - val_loss: 0.1382 - val_accuracy: 0.9413 - 53s/epoch - 2ms/step
Epoch 46/100
24468/24468 - 53s - loss: 0.1400 - accuracy: 0.9399 - val_loss: 0.1386 - val_accuracy: 0.9409 - 53s/epoch - 2ms/step
Epoch 47/100
24468/24468 - 53s - loss: 0.1372 - accuracy: 0.9406 - val_loss: 0.1367 - val_accuracy: 0.9412 - 53s/epoch - 2ms/step
Epoch 48/100
24468/24468 - 53s - loss: 0.1371 - accuracy: 0.9405 - val_loss: 0.1363 - val_accuracy: 0.9414 - 53s/epoch - 2ms/step
Epoch 49/100
24468/24468 - 53s - loss: 0.1368 - accuracy: 0.9405 - val_loss: 0.1467 - val_accuracy: 0.9392 - 53s/epoch - 2ms/step
Epoch 50/100
24468/24468 - 53s - loss: 0.1373 - accuracy: 0.9403 - val_loss: 0.1370 - val_accuracy: 0.9415 - 53s/epoch - 2ms/step
Epoch 51/100
24468/24468 - 53s - loss: 0.1370 - accuracy: 0.9404 - val_loss: 0.1420 - val_accuracy: 0.9356 - 53s/epoch - 2ms/step
Epoch 52/100
24468/24468 - 53s - loss: 0.1365 - accuracy: 0.9405 - val_loss: 0.1398 - val_accuracy: 0.9402 - 53s/epoch - 2ms/step
Epoch 53/100
24468/24468 - 53s - loss: 0.1364 - accuracy: 0.9406 - val_loss: 0.1418 - val_accuracy: 0.9395 - 53s/epoch - 2ms/step
Epoch 54/100
24468/24468 - 53s - loss: 0.1362 - accuracy: 0.9406 - val_loss: 0.1454 - val_accuracy: 0.9355 - 53s/epoch - 2ms/step
Epoch 55/100
24468/24468 - 53s - loss: 0.1364 - accuracy: 0.9406 - val_loss: 0.1369 - val_accuracy: 0.9412 - 53s/epoch - 2ms/step
Epoch 56/100
24468/24468 - 53s - loss: 0.1363 - accuracy: 0.9405 - val_loss: 0.1358 - val_accuracy: 0.9415 - 53s/epoch - 2ms/step
Epoch 57/100
24468/24468 - 53s - loss: 0.1368 - accuracy: 0.9405 - val_loss: 0.1375 - val_accuracy: 0.9405 - 53s/epoch - 2ms/step
Epoch 58/100
24468/24468 - 53s - loss: 0.1364 - accuracy: 0.9405 - val_loss: 0.1361 - val_accuracy: 0.9411 - 53s/epoch - 2ms/step
Epoch 59/100
24468/24468 - 53s - loss: 0.1381 - accuracy: 0.9402 - val_loss: 0.1367 - val_accuracy: 0.9407 - 53s/epoch - 2ms/step
Epoch 60/100
24468/24468 - 53s - loss: 0.1360 - accuracy: 0.9406 - val_loss: 0.1367 - val_accuracy: 0.9414 - 53s/epoch - 2ms/step
Epoch 61/100
24468/24468 - 53s - loss: 0.1362 - accuracy: 0.9406 - val_loss: 0.1374 - val_accuracy: 0.9408 - 53s/epoch - 2ms/step
Epoch 62/100
24468/24468 - 53s - loss: 0.1362 - accuracy: 0.9406 - val_loss: 0.1374 - val_accuracy: 0.9406 - 53s/epoch - 2ms/step
Epoch 63/100
24468/24468 - 53s - loss: 0.1361 - accuracy: 0.9406 - val_loss: 0.1370 - val_accuracy: 0.9404 - 53s/epoch - 2ms/step
Epoch 64/100
24468/24468 - 53s - loss: 0.1379 - accuracy: 0.9401 - val_loss: 0.1577 - val_accuracy: 0.9352 - 53s/epoch - 2ms/step
15293/15293 - 16s - loss: 0.1355 - accuracy: 0.9411 - 16s/epoch - 1ms/step
Test accuracy: 94.11%
15293/15293 - 12s - 12s/epoch - 783us/step
              precision    recall  f1-score   support

           0       0.86      0.96      0.91    133673
           1       1.00      1.00      1.00     56462
           2       0.87      0.48      0.62       122
           3       0.54      0.67      0.60        46
           4       1.00      1.00      1.00    133692
           5       1.00      1.00      1.00       346
           6       0.99      1.00      1.00      8291
           7       1.00      1.00      1.00     86977
           8       0.72      0.34      0.46      4218
           9       0.99      0.99      0.99      2057
          10       0.72      0.93      0.81      7869
          11       0.71      0.38      0.49     32121
          12       1.00      0.35      0.52        17
          13       1.00      1.00      1.00     23465

    accuracy                           0.94    489356
   macro avg       0.89      0.79      0.81    489356
weighted avg       0.94      0.94      0.93    489356

1
Tesla P100-PCIE-16GB
Instances: 7841683
Features: 80
Label
Benign                      668461
DDOS attack-HOIC            668461
DoS attacks-Hulk            434883
Bot                         282310
Infilteration               160705
SSH-Bruteforce              117322
DoS attacks-GoldenEye        41455
FTP-BruteForce               39346
DoS attacks-SlowHTTPTest     21092
DoS attacks-Slowloris        10285
DDOS attack-LOIC-UDP          1730
Brute Force -Web               609
Brute Force -XSS               230
SQL Injection                   87
Name: count, dtype: int64
Label
Benign                      668461
DDOS attack-HOIC            668461
DoS attacks-Hulk            434883
Bot                         282310
Infilteration               160705
SSH-Bruteforce              117322
DoS attacks-GoldenEye        41455
FTP-BruteForce               39346
DoS attacks-SlowHTTPTest     21092
DoS attacks-Slowloris        10285
DDOS attack-LOIC-UDP          1730
Brute Force -Web               609
Brute Force -XSS               230
SQL Injection                   87
Name: count, dtype: int64
{0: 'Benign', 1: 'Bot', 4: 'DDOS attack-HOIC', 6: 'DoS attacks-GoldenEye', 7: 'DoS attacks-Hulk', 11: 'Infilteration', 9: 'DoS attacks-Slowloris', 8: 'DoS attacks-SlowHTTPTest', 10: 'FTP-BruteForce', 13: 'SSH-Bruteforce', 2: 'Brute Force -Web', 5: 'DDOS attack-LOIC-UDP', 3: 'Brute Force -XSS', 12: 'SQL Injection'}
Intial values with Inf:          (2446976, 76)
Intial values after Inf removal: (2446780, 76)
Normalized shape: (2446780, 76) 

Shape of X_train: (1957424, 76)
Shape of y_train: (1957424,)
Shape of  X_test: (489356, 76)
Shape of  y_test: (489356,)
Label
7     534769
0     534769
6     534769
11    534769
4     534769
1     534769
13    534769
10    534769
9     534769
8     534769
5     534769
3     534769
2     534769
12    534769
Name: count, dtype: int64
Type of X_train: <class 'numpy.ndarray'>
Type of y_train: <class 'numpy.ndarray'>
Type of X_test: <class 'numpy.ndarray'>
Type of y_train: <class 'numpy.ndarray'>
14
14
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 reshape (Reshape)           (None, 76, 1)             0         
                                                                 
 conv1d (Conv1D)             (None, 74, 64)            256       
                                                                 
 batch_normalization (Batch  (None, 74, 64)            256       
 Normalization)                                                  
                                                                 
 max_pooling1d (MaxPooling1  (None, 37, 64)            0         
 D)                                                              
                                                                 
 conv1d_1 (Conv1D)           (None, 35, 128)           24704     
                                                                 
 batch_normalization_1 (Bat  (None, 35, 128)           512       
 chNormalization)                                                
                                                                 
 max_pooling1d_1 (MaxPoolin  (None, 17, 128)           0         
 g1D)                                                            
                                                                 
 conv1d_2 (Conv1D)           (None, 15, 256)           98560     
                                                                 
 batch_normalization_2 (Bat  (None, 15, 256)           1024      
 chNormalization)                                                
                                                                 
 max_pooling1d_2 (MaxPoolin  (None, 7, 256)            0         
 g1D)                                                            
                                                                 
 flatten (Flatten)           (None, 1792)              0         
                                                                 
 dense (Dense)               (None, 128)               229504    
                                                                 
 dense_1 (Dense)             (None, 128)               16512     
                                                                 
 dense_2 (Dense)             (None, 14)                1806      
                                                                 
=================================================================
Total params: 373134 (1.42 MB)
Trainable params: 372238 (1.42 MB)
Non-trainable params: 896 (3.50 KB)
_________________________________________________________________
Epoch 1/100
93585/93585 - 409s - loss: 0.2700 - accuracy: 0.8708 - val_loss: 5.6024 - val_accuracy: 0.4276 - 409s/epoch - 4ms/step
Epoch 2/100
93585/93585 - 396s - loss: 0.2177 - accuracy: 0.8965 - val_loss: 9.7656 - val_accuracy: 0.4185 - 396s/epoch - 4ms/step
Epoch 3/100
93585/93585 - 396s - loss: 0.2135 - accuracy: 0.8982 - val_loss: 12.0366 - val_accuracy: 0.4015 - 396s/epoch - 4ms/step
Epoch 4/100
93585/93585 - 396s - loss: 0.2078 - accuracy: 0.9007 - val_loss: 7.2988 - val_accuracy: 0.4230 - 396s/epoch - 4ms/step
Epoch 5/100
93585/93585 - 396s - loss: 0.2065 - accuracy: 0.9013 - val_loss: 5.4422 - val_accuracy: 0.4319 - 396s/epoch - 4ms/step
Epoch 6/100
93585/93585 - 395s - loss: 0.2064 - accuracy: 0.9011 - val_loss: 7.8056 - val_accuracy: 0.4285 - 395s/epoch - 4ms/step
Epoch 7/100
93585/93585 - 395s - loss: 0.2060 - accuracy: 0.9016 - val_loss: 8.8485 - val_accuracy: 0.4008 - 395s/epoch - 4ms/step
Epoch 8/100
93585/93585 - 395s - loss: 0.2031 - accuracy: 0.9028 - val_loss: 16.2372 - val_accuracy: 0.4221 - 395s/epoch - 4ms/step
Epoch 9/100
93585/93585 - 394s - loss: 0.2022 - accuracy: 0.9050 - val_loss: 533.6936 - val_accuracy: 0.3120 - 394s/epoch - 4ms/step
Epoch 10/100
93585/93585 - 394s - loss: 0.1951 - accuracy: 0.9091 - val_loss: 29.6718 - val_accuracy: 0.4143 - 394s/epoch - 4ms/step
Epoch 11/100
93585/93585 - 394s - loss: 0.1888 - accuracy: 0.9123 - val_loss: 14.2665 - val_accuracy: 0.4041 - 394s/epoch - 4ms/step
Epoch 12/100
93585/93585 - 394s - loss: 0.1858 - accuracy: 0.9139 - val_loss: 30.1340 - val_accuracy: 0.4010 - 394s/epoch - 4ms/step
Epoch 13/100
93585/93585 - 394s - loss: 0.1821 - accuracy: 0.9152 - val_loss: 6.7564 - val_accuracy: 0.3928 - 394s/epoch - 4ms/step
Epoch 14/100
93585/93585 - 394s - loss: 0.1846 - accuracy: 0.9145 - val_loss: 8823.3926 - val_accuracy: 0.0546 - 394s/epoch - 4ms/step
Epoch 15/100
93585/93585 - 394s - loss: 0.1806 - accuracy: 0.9159 - val_loss: 10.5598 - val_accuracy: 0.4318 - 394s/epoch - 4ms/step
Epoch 16/100
93585/93585 - 394s - loss: 0.1817 - accuracy: 0.9160 - val_loss: 10.8281 - val_accuracy: 0.3984 - 394s/epoch - 4ms/step
Epoch 17/100
93585/93585 - 394s - loss: 0.1814 - accuracy: 0.9163 - val_loss: 8772.4990 - val_accuracy: 0.4229 - 394s/epoch - 4ms/step
Epoch 18/100
93585/93585 - 393s - loss: 0.2657 - accuracy: 0.8734 - val_loss: 6.6577 - val_accuracy: 0.4223 - 393s/epoch - 4ms/step
Epoch 19/100
93585/93585 - 392s - loss: 0.2422 - accuracy: 0.8841 - val_loss: 6.3067 - val_accuracy: 0.4228 - 392s/epoch - 4ms/step
Epoch 20/100
93585/93585 - 392s - loss: 0.2198 - accuracy: 0.8962 - val_loss: 12.3841 - val_accuracy: 0.4160 - 392s/epoch - 4ms/step
Epoch 21/100
93585/93585 - 392s - loss: 0.2637 - accuracy: 0.8742 - val_loss: 17.6927 - val_accuracy: 0.4238 - 392s/epoch - 4ms/step
Epoch 22/100
93585/93585 - 392s - loss: 0.2679 - accuracy: 0.8693 - val_loss: 10.1257 - val_accuracy: 0.4272 - 392s/epoch - 4ms/step
Epoch 23/100
93585/93585 - 392s - loss: 0.2652 - accuracy: 0.8703 - val_loss: 10.3561 - val_accuracy: 0.4253 - 392s/epoch - 4ms/step
Epoch 24/100
93585/93585 - 392s - loss: 0.2636 - accuracy: 0.8706 - val_loss: 9.4498 - val_accuracy: 0.3946 - 392s/epoch - 4ms/step
Epoch 25/100
93585/93585 - 392s - loss: 0.2617 - accuracy: 0.8710 - val_loss: 11.1353 - val_accuracy: 0.4195 - 392s/epoch - 4ms/step
15293/15293 - 22s - loss: 0.2294 - accuracy: 0.9074 - 22s/epoch - 1ms/step
Test accuracy: 90.74%
15293/15293 - 17s - 17s/epoch - 1ms/step
15293/15293 - 18s - 18s/epoch - 1ms/step
              precision    recall  f1-score   support

           0       0.86      0.94      0.90    133673
           1       0.99      0.97      0.98     56462
           2       0.04      0.75      0.07       122
           3       0.02      0.87      0.04        46
           4       1.00      1.00      1.00    133692
           5       0.99      1.00      1.00       346
           6       0.44      1.00      0.61      8291
           7       1.00      0.88      0.94     86977
           8       0.47      0.88      0.61      4219
           9       0.82      1.00      0.90      2057
          10       0.88      0.47      0.62      7869
          11       0.69      0.37      0.48     32121
          12       0.00      0.00      0.00        17
          13       1.00      1.00      1.00     23464

    accuracy                           0.91    489356
   macro avg       0.66      0.79      0.65    489356
weighted avg       0.92      0.91      0.91    489356

Epoch 1/100
93585/93585 - 200s - loss: 0.3006 - accuracy: 0.8558 - val_loss: 4.4424 - val_accuracy: 0.4243 - 200s/epoch - 2ms/step
Epoch 2/100
93585/93585 - 199s - loss: 0.2452 - accuracy: 0.8829 - val_loss: 4.3259 - val_accuracy: 0.5338 - 199s/epoch - 2ms/step
Epoch 3/100
93585/93585 - 199s - loss: 0.2204 - accuracy: 0.8980 - val_loss: 4.3964 - val_accuracy: 0.4769 - 199s/epoch - 2ms/step
Epoch 4/100
93585/93585 - 199s - loss: 0.2082 - accuracy: 0.9010 - val_loss: 5.9678 - val_accuracy: 0.4545 - 199s/epoch - 2ms/step
Epoch 5/100
93585/93585 - 199s - loss: 0.2065 - accuracy: 0.9016 - val_loss: 4.5616 - val_accuracy: 0.5540 - 199s/epoch - 2ms/step
Epoch 6/100
93585/93585 - 199s - loss: 0.2037 - accuracy: 0.9021 - val_loss: 4.2797 - val_accuracy: 0.5088 - 199s/epoch - 2ms/step
Epoch 7/100
93585/93585 - 199s - loss: 0.2038 - accuracy: 0.9020 - val_loss: 5.1243 - val_accuracy: 0.4820 - 199s/epoch - 2ms/step
Epoch 8/100
93585/93585 - 199s - loss: 0.2036 - accuracy: 0.9026 - val_loss: 5.2005 - val_accuracy: 0.4695 - 199s/epoch - 2ms/step
Epoch 9/100
93585/93585 - 199s - loss: 0.2009 - accuracy: 0.9031 - val_loss: 4.5319 - val_accuracy: 0.5363 - 199s/epoch - 2ms/step
Epoch 10/100
93585/93585 - 199s - loss: 0.2005 - accuracy: 0.9032 - val_loss: 4.3196 - val_accuracy: 0.5529 - 199s/epoch - 2ms/step
Epoch 11/100
93585/93585 - 199s - loss: 0.1998 - accuracy: 0.9033 - val_loss: 4.9788 - val_accuracy: 0.5532 - 199s/epoch - 2ms/step
Epoch 12/100
93585/93585 - 199s - loss: 0.1992 - accuracy: 0.9036 - val_loss: 7.8053 - val_accuracy: 0.5338 - 199s/epoch - 2ms/step
Epoch 13/100
93585/93585 - 199s - loss: 0.1986 - accuracy: 0.9038 - val_loss: 6.1661 - val_accuracy: 0.4350 - 199s/epoch - 2ms/step
Epoch 14/100
93585/93585 - 199s - loss: 0.1980 - accuracy: 0.9039 - val_loss: 5.5366 - val_accuracy: 0.5456 - 199s/epoch - 2ms/step
Epoch 15/100
93585/93585 - 199s - loss: 0.1976 - accuracy: 0.9040 - val_loss: 6.1633 - val_accuracy: 0.5712 - 199s/epoch - 2ms/step
Epoch 16/100
93585/93585 - 199s - loss: 0.1973 - accuracy: 0.9041 - val_loss: 8.1534 - val_accuracy: 0.5572 - 199s/epoch - 2ms/step
Epoch 17/100
93585/93585 - 199s - loss: 0.1967 - accuracy: 0.9043 - val_loss: 6.8802 - val_accuracy: 0.5459 - 199s/epoch - 2ms/step
Epoch 18/100
93585/93585 - 199s - loss: 0.1961 - accuracy: 0.9045 - val_loss: 7.0321 - val_accuracy: 0.4251 - 199s/epoch - 2ms/step
Epoch 19/100
93585/93585 - 199s - loss: 0.1962 - accuracy: 0.9047 - val_loss: 6.0104 - val_accuracy: 0.4948 - 199s/epoch - 2ms/step
Epoch 20/100
93585/93585 - 199s - loss: 0.1954 - accuracy: 0.9048 - val_loss: 4.9844 - val_accuracy: 0.5077 - 199s/epoch - 2ms/step
Epoch 21/100
93585/93585 - 199s - loss: 0.1951 - accuracy: 0.9051 - val_loss: 8.9688 - val_accuracy: 0.5058 - 199s/epoch - 2ms/step
Epoch 22/100
93585/93585 - 199s - loss: 0.1946 - accuracy: 0.9053 - val_loss: 6.3212 - val_accuracy: 0.4838 - 199s/epoch - 2ms/step
Epoch 23/100
93585/93585 - 199s - loss: 0.1939 - accuracy: 0.9057 - val_loss: 7.3267 - val_accuracy: 0.4791 - 199s/epoch - 2ms/step
Epoch 24/100
93585/93585 - 199s - loss: 0.1932 - accuracy: 0.9064 - val_loss: 7.9504 - val_accuracy: 0.5495 - 199s/epoch - 2ms/step
Epoch 25/100
93585/93585 - 199s - loss: 0.1910 - accuracy: 0.9080 - val_loss: 5.4467 - val_accuracy: 0.5687 - 199s/epoch - 2ms/step
Epoch 26/100
93585/93585 - 199s - loss: 0.1883 - accuracy: 0.9099 - val_loss: 6.9920 - val_accuracy: 0.5611 - 199s/epoch - 2ms/step
15293/15293 - 16s - loss: 0.1644 - accuracy: 0.9298 - 16s/epoch - 1ms/step
Test accuracy: 92.98%
15293/15293 - 12s - 12s/epoch - 778us/step
15293/15293 - 13s - 13s/epoch - 819us/step
              precision    recall  f1-score   support

           0       0.87      0.94      0.90    133673
           1       1.00      0.98      0.99     56462
           2       0.04      0.72      0.07       122
           3       0.03      0.85      0.06        46
           4       1.00      1.00      1.00    133692
           5       0.99      1.00      1.00       346
           6       0.99      1.00      0.99      8291
           7       1.00      1.00      1.00     86977
           8       0.46      0.92      0.61      4219
           9       0.89      1.00      0.94      2057
          10       0.90      0.42      0.57      7869
          11       0.68      0.39      0.49     32121
          12       0.50      0.06      0.11        17
          13       1.00      1.00      1.00     23464

    accuracy                           0.93    489356
   macro avg       0.74      0.80      0.70    489356
weighted avg       0.93      0.93      0.93    489356

